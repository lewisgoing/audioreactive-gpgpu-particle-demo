<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Audio Reactive GPGPU Particles</title>
    <script src="https://cdn.tailwindcss.com"></script>
    <style>
        body {
            font-family: 'Inter', sans-serif;
            margin: 0;
            padding: 0;
            overflow: hidden;
            background-color: #111827; /* bg-gray-900 */
            color: #f3f4f6; /* text-gray-100 */
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            flex-direction: column;
        }
        #canvas-container {
            display: flex;
            justify-content: center;
            align-items: center;
            flex-direction: column;
            max-width: 95vw;
            max-height: 95vh;
        }
        canvas {
            background-color: #000;
            border-radius: 0.5rem;
            box-shadow: 0 0 20px rgba(139, 92, 246, 0.5); /* shadow-violet-500/50 */
        }
        .upload-wrapper {
            margin-top: 1.5rem; /* mt-6 */
            text-align: center;
        }
        #audio-upload {
            display: none;
        }
        .upload-label {
            cursor: pointer;
            padding: 0.75rem 1.5rem; /* py-3 px-6 */
            background-color: #4f46e5; /* bg-indigo-600 */
            color: white;
            border-radius: 0.5rem; /* rounded-lg */
            transition: background-color 0.3s ease, transform 0.2s ease;
            font-weight: 600;
            box-shadow: 0 4px 6px -1px rgba(0, 0, 0, 0.1), 0 2px 4px -2px rgba(0, 0, 0, 0.1);
        }
        .upload-label:hover {
            background-color: #6366f1; /* hover:bg-indigo-500 */
            transform: translateY(-2px);
        }
        .upload-label:active {
            transform: translateY(0);
        }
        #info-text {
            margin-top: 0.5rem;
            font-size: 0.875rem; /* text-sm */
            color: #9ca3af; /* text-gray-400 */
        }
    </style>
</head>
<body>
    <div id="canvas-container">
        <canvas id="webgl-canvas"></canvas>
        <div class="upload-wrapper">
            <label for="audio-upload" class="upload-label">Upload Audio</label>
            <input type="file" id="audio-upload" accept="audio/*">
            <p id="info-text">Animation will respond to the loaded audio file.</p>
        </div>
    </div>

    <!-- Shader definitions -->
    <script id="vertexShader" type="x-shader/x-vertex">
        attribute vec3 position;
        void main(void){
            gl_Position = vec4(position, 1.0);
        }
    </script>

    <script id="fragmentShader" type="x-shader/x-fragment">
        precision mediump float;
        uniform vec2 resolution;
        void main(void){
            vec2 p = (gl_FragCoord.xy / resolution) * 2.0 - 1.0;
            // Add a little randomness to the initial position
            float random = fract(sin(dot(p, vec2(12.9898, 78.233))) * 43758.5453);
            gl_FragColor = vec4(p * (0.9 + random * 0.1), 0.0, 1.0);
        }
    </script>

    <script id="pointVs" type="x-shader/x-vertex">
        attribute float index;
        uniform vec2 resolution;
        uniform sampler2D texture;
        uniform float pointScale;
        uniform float audio; // uniform for audio data
        void main(void){
            vec2 p = vec2(mod(index, resolution.x) / resolution.x, floor(index / resolution.x) / resolution.y);
            vec4 t = texture2D(texture, p);
            // Change point size according to audio data
            gl_PointSize = (0.1 + pointScale) * (1.0 + audio * 5.0);
            gl_Position = vec4(t.xy, 0.0, 1.0);
        }
    </script>

    <script id="pointFs" type="x-shader/x-fragment">
        precision mediump float;
        uniform vec4 ambient;
        void main(void){
            gl_FragColor = ambient;
        }
    </script>

    <script id="velocityVs" type="x-shader/x-vertex">
        attribute vec3 position;
        void main(void){
            gl_Position = vec4(position, 1.0);
        }
    </script>

    <script id="velocityFs" type="x-shader/x-fragment">
        precision mediump float;
        uniform vec2 resolution;
        uniform sampler2D texture;
        uniform vec2 mouse;
        uniform bool mouseFlag;
        uniform float velocity;
        uniform float audio; // uniform for audio data
        uniform float time;  // uniform for time

        const float SPEED = 0.01;

        void main(void){
            vec2 p = gl_FragCoord.xy / resolution;
            vec4 t = texture2D(texture, p);

            // Determine the position of the attractor (the point that pulls)
            vec2 attractor;
            if(mouseFlag){
                // When the mouse is pressed, use the mouse cursor as the attractor
                attractor = mouse;
            } else {
                // When the mouse is not pressed, use a point moving over time as the attractor
                attractor.x = sin(time * 0.3) * 0.8;
                attractor.y = cos(time * 0.2) * 0.8;
            }

            // Vector towards the attractor
            vec2 v = normalize(attractor - t.xy) * 0.1;

            // Correct the direction
            vec2 w = normalize(v + t.zw);

            // Change speed according to audio data and velocity
            float currentSpeed = SPEED * (velocity + audio * 2.0);
            
            // Prevent going off-screen
            vec2 nextPos = t.xy + w * currentSpeed;
            nextPos = clamp(nextPos, -1.0, 1.0);

            vec4 destColor = vec4(nextPos, w);

            gl_FragColor = destColor;
        }
    </script>

    <script type="module">
        //===============================================================
        // Init & Rendering
        //===============================================================
        let canvas, gl;
        let prg, attLocation, attStride, uniLocation;
        let pPrg, pAttLocation, pAttStride, pUniLocation;
        let vPrg, vAttLocation, vAttStride, vUniLocation;
        let position, vVBOList, planeVBOList;
        let vertices, resolution, ambient;
        let backBuffer, frontBuffer, flip;
        let velocity = 0.0;
        let mouseFlag = false;
        let mousePositionX = 0.0;
        let mousePositionY = 0.0;
        let count = 0;

        // Audio variables
        let audioContext, analyser, audioSource, dataArray;
        let audioInitialized = false;

        const TEXTURE_WIDTH = 512;
        const TEXTURE_HEIGHT = 512;

        function init() {
            canvas = document.getElementById('webgl-canvas');
            const size = Math.min(window.innerWidth * 0.8, window.innerHeight * 0.7, 800);
            canvas.width = size;
            canvas.height = size;

            gl = canvas.getContext('webgl');

            if (!gl) {
                console.error("WebGL not supported!");
                return;
            }

            const vtf = gl.getParameter(gl.MAX_VERTEX_TEXTURE_IMAGE_UNITS);
            if (vtf <= 0) {
                console.error('Vertex Texture Fetch not supported');
                return;
            }

            const ext = gl.getExtension('OES_texture_float');
            if (!ext) {
                console.error('Float texture not supported');
                return;
            }

            // Fetch shader sources
            const vertexShaderSource = document.getElementById('vertexShader').textContent;
            const fragmentShaderSource = document.getElementById('fragmentShader').textContent;
            const pointVsSource = document.getElementById('pointVs').textContent;
            const pointFsSource = document.getElementById('pointFs').textContent;
            const velocityVsSource = document.getElementById('velocityVs').textContent;
            const velocityFsSource = document.getElementById('velocityFs').textContent;

            // Shader for initial positions
            const vShader = createShader(gl.VERTEX_SHADER, vertexShaderSource);
            const fShader = createShader(gl.FRAGMENT_SHADER, fragmentShaderSource);
            prg = createProgram(vShader, fShader);
            attLocation = [gl.getAttribLocation(prg, 'position')];
            attStride = [3];
            uniLocation = [gl.getUniformLocation(prg, 'resolution')];

            // Shader for rendering points
            const vShader2 = createShader(gl.VERTEX_SHADER, pointVsSource);
            const fShader2 = createShader(gl.FRAGMENT_SHADER, pointFsSource);
            pPrg = createProgram(vShader2, fShader2);
            pAttLocation = [gl.getAttribLocation(pPrg, 'index')];
            pAttStride = [1];
            pUniLocation = [
                gl.getUniformLocation(pPrg, 'resolution'),
                gl.getUniformLocation(pPrg, 'texture'),
                gl.getUniformLocation(pPrg, 'pointScale'),
                gl.getUniformLocation(pPrg, 'ambient'),
                gl.getUniformLocation(pPrg, 'audio')
            ];

            // Shader for updating positions via framebuffer feedback
            const vShader3 = createShader(gl.VERTEX_SHADER, velocityVsSource);
            const fShader3 = createShader(gl.FRAGMENT_SHADER, velocityFsSource);
            vPrg = createProgram(vShader3, fShader3);
            vAttLocation = [gl.getAttribLocation(vPrg, 'position')];
            vAttStride = [3];
            vUniLocation = [
                gl.getUniformLocation(vPrg, 'resolution'),
                gl.getUniformLocation(vPrg, 'texture'),
                gl.getUniformLocation(vPrg, 'mouse'),
                gl.getUniformLocation(vPrg, 'mouseFlag'),
                gl.getUniformLocation(vPrg, 'velocity'),
                gl.getUniformLocation(vPrg, 'audio'),
                gl.getUniformLocation(vPrg, 'time')
            ];

            resolution = [TEXTURE_WIDTH, TEXTURE_HEIGHT];
            vertices = Array.from({ length: TEXTURE_WIDTH * TEXTURE_HEIGHT }, (_, i) => i);
            const vIndex = createVbo(vertices);
            vVBOList = [vIndex];

            position = [-1.0, 1.0, 0.0, -1.0, -1.0, 0.0, 1.0, 1.0, 0.0, 1.0, -1.0, 0.0];
            const vPlane = createVbo(position);
            planeVBOList = [vPlane];

            backBuffer = createFramebuffer(TEXTURE_WIDTH, TEXTURE_HEIGHT, gl.FLOAT);
            frontBuffer = createFramebuffer(TEXTURE_WIDTH, TEXTURE_HEIGHT, gl.FLOAT);

            gl.disable(gl.BLEND);
            gl.blendFunc(gl.ONE, gl.ONE);

            // Initialize back buffer with initial positions
            gl.bindFramebuffer(gl.FRAMEBUFFER, backBuffer.f);
            gl.viewport(0, 0, TEXTURE_WIDTH, TEXTURE_HEIGHT);
            gl.clearColor(0.0, 0.0, 0.0, 0.0);
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.useProgram(prg);
            setAttribute(planeVBOList, attLocation, attStride);
            gl.uniform2fv(uniLocation[0], resolution);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, position.length / 3);

            ambient = [];

            window.addEventListener('mousedown', mouseDown, true);
            window.addEventListener('mouseup', mouseUp, true);
            window.addEventListener('mousemove', mouseMove, true);
            
            document.getElementById('audio-upload').addEventListener('change', setupAudio);
        }

        function setupAudio(event) {
            if (audioInitialized) return;
            const file = event.target.files[0];
            if (!file) return;

            const audio = new Audio();
            audio.src = URL.createObjectURL(file);
            audio.loop = true;

            audioContext = new (window.AudioContext || window.webkitAudioContext)();
            analyser = audioContext.createAnalyser();
            analyser.fftSize = 256;
            
            audioSource = audioContext.createMediaElementSource(audio);
            audioSource.connect(analyser);
            analyser.connect(audioContext.destination);

            const bufferLength = analyser.frequencyBinCount;
            dataArray = new Uint8Array(bufferLength);
            
            audio.play().then(() => {
                audioInitialized = true;
                document.getElementById('info-text').textContent = "Playing... you can manipulate particles with the mouse.";
            }).catch(e => console.error("Audio playback failed:", e));
        }

        function rendering() {
            count++;
            let audioValue = 0.0;
            if (audioInitialized) {
                analyser.getByteFrequencyData(dataArray);
                let sum = 0;
                for (let i = 0; i < dataArray.length / 4; i++) {
                    sum += dataArray[i];
                }
                audioValue = (sum / (dataArray.length / 4)) / 255.0;
            }

            gl.disable(gl.BLEND);
            gl.bindFramebuffer(gl.FRAMEBUFFER, frontBuffer.f);
            gl.viewport(0, 0, TEXTURE_WIDTH, TEXTURE_HEIGHT);
            gl.clearColor(0.0, 0.0, 0.0, 0.0);
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.useProgram(vPrg);
            gl.bindTexture(gl.TEXTURE_2D, backBuffer.t);
            setAttribute(planeVBOList, vAttLocation, vAttStride);
            gl.uniform2fv(vUniLocation[0], resolution);
            gl.uniform1i(vUniLocation[1], 0);
            gl.uniform2fv(vUniLocation[2], [mousePositionX, mousePositionY]);
            gl.uniform1i(vUniLocation[3], mouseFlag);
            gl.uniform1f(vUniLocation[4], velocity);
            gl.uniform1f(vUniLocation[5], audioValue);
            gl.uniform1f(vUniLocation[6], count * 0.01);
            gl.drawArrays(gl.TRIANGLE_STRIP, 0, position.length / 3);

            ambient = hsva(count % 360, 1.0, 0.8, 1.0);

            gl.enable(gl.BLEND);
            gl.viewport(0, 0, canvas.width, canvas.height);
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            gl.clearColor(0.05, 0.05, 0.1, 1.0);
            gl.clear(gl.COLOR_BUFFER_BIT);
            gl.useProgram(pPrg);
            gl.bindTexture(gl.TEXTURE_2D, frontBuffer.t);
            setAttribute(vVBOList, pAttLocation, pAttStride);
            gl.uniform2fv(pUniLocation[0], resolution);
            gl.uniform1i(pUniLocation[1], 0);
            gl.uniform1f(pUniLocation[2], velocity);
            gl.uniform4fv(pUniLocation[3], ambient);
            gl.uniform1f(pUniLocation[4], audioValue);
            gl.drawArrays(gl.POINTS, 0, vertices.length);

            gl.flush();

            if (mouseFlag) {
                velocity = 1.0;
            } else {
                velocity = Math.max(0.2, velocity * 0.95);
            }

            flip = backBuffer;
            backBuffer = frontBuffer;
            frontBuffer = flip;

            requestAnimationFrame(rendering);
        }

        //===============================================================
        // Control handlers
        //===============================================================
        function mouseDown(event) { mouseFlag = true; }
        function mouseUp(event) { mouseFlag = false; }
        function mouseMove(event) {
            if (mouseFlag) {
                const rect = canvas.getBoundingClientRect();
                mousePositionX = (event.clientX - rect.left - canvas.width / 2.0) / (canvas.width / 2.0);
                mousePositionY = -(event.clientY - rect.top - canvas.height / 2.0) / (canvas.height / 2.0);
            }
        }

        //===============================================================
        // Utility Functions
        //===============================================================
        function createShader(shaderType, shaderText) {
            const shader = gl.createShader(shaderType);
            gl.shaderSource(shader, shaderText);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
                return null;
            }
            return shader;
        }

        function createProgram(vs, fs) {
            const program = gl.createProgram();
            gl.attachShader(program, vs);
            gl.attachShader(program, fs);
            gl.linkProgram(program);
            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error(gl.getProgramInfoLog(program));
                return null;
            }
            gl.useProgram(program);
            return program;
        }

        function createVbo(data) {
            const vbo = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, vbo);
            gl.bufferData(gl.ARRAY_BUFFER, new Float32Array(data), gl.STATIC_DRAW);
            gl.bindBuffer(gl.ARRAY_BUFFER, null);
            return vbo;
        }

        function setAttribute(vbo, attL, attS) {
            for (let i in vbo) {
                gl.bindBuffer(gl.ARRAY_BUFFER, vbo[i]);
                gl.enableVertexAttribArray(attL[i]);
                gl.vertexAttribPointer(attL[i], attS[i], gl.FLOAT, false, 0, 0);
            }
        }

        function createFramebuffer(width, height, format) {
            const textureFormat = format || gl.UNSIGNED_BYTE;
            const frameBuffer = gl.createFramebuffer();
            gl.bindFramebuffer(gl.FRAMEBUFFER, frameBuffer);
            const fTexture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, fTexture);
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA, width, height, 0, gl.RGBA, textureFormat, null);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MAG_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_MIN_FILTER, gl.NEAREST);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_S, gl.CLAMP_TO_EDGE);
            gl.texParameteri(gl.TEXTURE_2D, gl.TEXTURE_WRAP_T, gl.CLAMP_TO_EDGE);
            gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, fTexture, 0);
            gl.bindTexture(gl.TEXTURE_2D, null);
            gl.bindFramebuffer(gl.FRAMEBUFFER, null);
            return { f: frameBuffer, t: fTexture };
        }

        function hsva(h, s, v, a) {
            if (s > 1 || v > 1 || a > 1) { return; }
            let th = h % 360;
            let i = Math.floor(th / 60);
            let f = th / 60 - i;
            let m = v * (1 - s);
            let n = v * (1 - s * f);
            let k = v * (1 - s * (1 - f));
            let color = new Array();
            if (!s > 0 && !s < 0) {
                color.push(v, v, v, a);
            } else {
                let r = new Array(v, n, m, m, k, v);
                let g = new Array(k, v, v, n, m, m);
                let b = new Array(m, m, k, v, v, n);
                color.push(r[i], g[i], b[i], a);
            }
            return color;
        }

        window.addEventListener('load', () => {
            init();
            rendering();
        });
    </script>
</body>
</html>
